{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e16af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199,"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "min=2000\n",
    "max=3200\n",
    "for i in range (min,max+1):\n",
    "    if(i%7==0 and (not(i%5==0))):\n",
    "        print(i, end = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f4775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lower case letter is: 8\n",
      "The number of upper case letter is: 3\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "s = \" I Love Python\"\n",
    "upper = sum(1 for element in s if element.isupper())\n",
    "lower = sum(1 for element in s if element.islower())\n",
    "print(\"The number of lower case letter is:\",lower)\n",
    "print(\"The number of upper case letter is:\",upper)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7dbd535",
   "metadata": {},
   "source": [
    "#Q3\n",
    "To reduced dimensionality we can seperate data on the basis of numerical and categorical variables.\n",
    "For numerical data we use correlation and for categorical we will use hypothesis test.\n",
    "We can also use Principle Component Analysis to reduce dimensionality of the data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "caa5f9d8",
   "metadata": {},
   "source": [
    "#Q4\n",
    "In the case of cancer we interested in minority class which is patients who actually have cancer. In our case the ratio is only 4% and the majority class is 96%. If we have worked on enough data sets, we should deduce that cancer detection results in imbalanced data.In an imbalanced dataset,accuracy should not be used as a measure of performance. For imbalanced dataset we used Precision, Recall and calculate F1 score for getting model performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "46b0d841",
   "metadata": {},
   "source": [
    "#Q4\n",
    "* Prior Probability : The probability of each class before any characteristics are observed.\n",
    "* Likehood : Likelihood is calculated using the training data by counting the number of objects in each class that possess each feature.\n",
    "* Marginal Likehood : The marginal likelihood is determined by adding the prior probability and the likelihood for each class.\n",
    "\n",
    "            P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "Where,\n",
    "P(E) is the marginal likelihood\n",
    "P(H|E) is the posterior probability \n",
    "P(E|H) is the likelihood "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a619ed64",
   "metadata": {},
   "source": [
    "Q5\n",
    "Yes, We get higher accuracy than Decision Tree model if we use Regression model for time series dataset.\n",
    "Decision tree fails to predict because the linear relationship can not map in decision tree."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ee7f58a",
   "metadata": {},
   "source": [
    "Q6\n",
    "In such situation we use Bagging algorithm. because it divides a data set into subsets made with repeated randomized sampling. Then, these samples are used to generate a set of models using a single learning algorithm."
   ]
  },
  {
   "cell_type": "raw",
   "id": "26fd1278",
   "metadata": {},
   "source": [
    "Q7\n",
    "Yes we remove correlated variable because PCA put more importance on correlated variable, which is misleading."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3231e63d",
   "metadata": {},
   "source": [
    "Q8\n",
    "To check multicollinearity, we can create a correlation matrix to identify and to built better model we can use penalized regression models like ridge or lasso regression."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b33454e",
   "metadata": {},
   "source": [
    "Q9\n",
    "Ridge regression is favorable over Lasso regression when all the features in the dataset are important and none of them can be removed. Ridge regression is also preferred when the number of features is greater than the number of observations. To select important variables from a dataset, you can use methods such as univariate feature selection, recursive feature elimination, and regularization methods such as L1 or L2 regularization."
   ]
  },
  {
   "cell_type": "raw",
   "id": "efd3ee6f",
   "metadata": {},
   "source": [
    "Q10\n",
    "A classification trees makes decision based on Gini Index and Node Entropy.The tree algorithm find the best possible feature which can divide the data set into purest possible children nodes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f72a963a",
   "metadata": {},
   "source": [
    "Q11\n",
    "OLS cannot be used because in such high dimensional data sets, we canâ€™t use classical regression techniques, since their assumptions tend to fail. When p > n, the variances become infinite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fe8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100, 11: 121, 12: 144, 13: 169, 14: 196, 15: 225, 16: 256, 17: 289, 18: 324, 19: 361, 20: 400}\n"
     ]
    }
   ],
   "source": [
    "#Q12\n",
    "d = dict()\n",
    "for x in range(1, 21):\n",
    "    d[x] = x ** 2\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef2cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Half: (1, 2, 3, 4, 5)\n",
      "Last Half: (6, 7, 8, 9, 10)\n"
     ]
    }
   ],
   "source": [
    "#Q13\n",
    "tup = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "mid = len(tup) // 2\n",
    "print(\"First Half:\", tup[:mid])\n",
    "print(\"Last Half:\", tup[mid:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66e8a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 5 random even numbers between 100 and 200: [200, 160, 114, 184, 100]\n"
     ]
    }
   ],
   "source": [
    "#Q14\n",
    "import random\n",
    "even_num = []\n",
    "while len(even_num) < 5:\n",
    "    number = random.randint(100, 200)\n",
    "    if number % 2 == 0:\n",
    "        even_num.append(number)\n",
    "print(\"List of 5 random even numbers between 100 and 200:\", even_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec226aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Gender\n",
      "Male\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "#Q 15\n",
    "class Person:\n",
    "    def getGender(self):\n",
    "        print(\"Unknown Gender\")\n",
    "\n",
    "class Male(Person):\n",
    "    def getGender(self):\n",
    "        print(\"Male\")\n",
    "\n",
    "class Female(Person):\n",
    "    def getGender(self):\n",
    "        print(\"Female\")\n",
    "person = Person()\n",
    "male = Male()\n",
    "female = Female()\n",
    "\n",
    "person.getGender() \n",
    "male.getGender()    \n",
    "female.getGender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf8c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
